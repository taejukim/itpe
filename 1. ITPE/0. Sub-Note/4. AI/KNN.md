#AI #머신러닝 #분류 #필수

## 정의
가장 가까운 K개 이웃을 기반으로 분류하는 알고리즘, KNN
- 새로운 데이터가 주어졌을 때, 가장 가까운 K개의 이웃 데이터를 찾아 다수결로 분류하는 지도학습 알고리즘
- 별도의 학습 과정 없이 데이터를 저장하고 예측 시 계산 (Lazy Learning)
## 키워드
* K-Nearest Neighbors, 거리 측정, 다수결, Lazy Learning
## 암기법
* KNN = K개의 가장 가까운 이웃으로 분류
* 거리: ==유맨민코== (유클리드, 맨해튼, 민코프스키, 코사인)
## 연관 토픽
- [[서포트 벡터 머신 SVM]] - 분류 알고리즘
- [[DBSCAN(밀도 기반 클러스터링)]] - 클러스터링
- [[PCA(주성분분석)]] - 차원 축소
## 동작 원리
```
┌─────────────────────────────────────────────────┐
│              KNN 분류 (K=3)                      │
│                                                 │
│        ○ ○                                      │
│      ○   ○ ○                                    │
│        ★ ○     ← 새로운 데이터 (★)                 │
│      ● ●                                        │
│        ● ●                                      │
│                                                 │
│  가장 가까운 3개: ○ ○ ●                            │
│  다수결: ○ (2개) > ● (1개)                         │
│  결과: ★ → ○ 클래스로 분류                          │
└─────────────────────────────────────────────────┘
```
## 거리 측정 방법
| 방법        | 수식                     | 특징     |
| --------- | ---------------------- | ------ |
| ==유클리드==  | √Σ(x_i - y_i)²         | 가장 일반적 |
| ==맨해튼==   | Σ(\|x_i - y_i\|)       | 격자형 거리 |
| ==민코프스키== | (Σ\|x_i - y_i\|)^(1/p) | 일반화    |
| ==코사인==   |  cos(y)- cos(x)        | 방향 유사도 |
;
## K 값 선택
| K 값 | 특징 |
|------|------|
| K 작음 | 노이즈에 민감, 과적합 위험 |
| K 큼 | 결정 경계 부드러움, 과소적합 위험 |
| 최적 K | 교차 검증으로 결정 |
## 장단점
| 장점 | 단점 |
|------|------|
| 단순하고 직관적 | 계산 비용 높음 (예측 시) |
| 학습 불필요 | 고차원에서 성능 저하 |
| 비선형 경계 가능 | 메모리 많이 필요 |
| 다중 클래스 지원 | 특성 스케일 민감 |
## 개선 방법
- ==정규화==: 특성 스케일 맞추기
- ==가중치 KNN==: 거리에 따른 가중치 부여
- ==KD-Tree==: 빠른 이웃 탐색
- ==Ball Tree==: 고차원 데이터 탐색
## 활용 분야
- 추천 시스템 (협업 필터링)
- 위치 측위
- 선호도 분류
- 이미지 분류
- 이상 탐지
- 결측치 대체
