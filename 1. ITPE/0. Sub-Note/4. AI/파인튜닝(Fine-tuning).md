#AI #LLM #학습 #필수

## 정의
사전 학습된 모델을 특정 작업에 맞게 조정하는 기법, 파인튜닝
- 대규모 데이터로 사전 학습된 모델의 가중치를 특정 도메인이나 작업에 맞게 추가 학습하는 과정
- 적은 데이터로 높은 성능 달성 가능
## 키워드
* Fine-tuning, LoRA, QLoRA, Adapter, 전이학습, 도메인 특화
## 암기법
* Fine-tuning = Fine(미세) + Tuning(조정)
* 효율적 방법: ==LoRA, QLoRA, Adapter==
## 학습 과정
```
┌─────────────────────────────────────────────────┐
│              파인튜닝 과정                         │
│                                                 │
│  [사전학습 모델]  →  [도메인 데이터]  →  [특화 모델]     │
│   (Pre-trained)   (Fine-tuning)  (Specialized)  │
│                                                 │
│  예: GPT-4 Base  →  의료 데이터 학습  →  의료 GPT    │
└─────────────────────────────────────────────────┘
```
## 연관 토픽
- [[인공지능 파운데이션 모델]] - 기반 모델
- [[LLM]] - 대규모 언어 모델
- [[RAG(Retrieval Augmented Generation)]] - 검색 증강
## 파인튜닝 유형
| 유형 | 설명 | 특징 |
|------|------|------|
| ==Full Fine-tuning== | 전체 파라미터 학습 | 높은 성능, 높은 비용 |
| ==LoRA== | 저랭크 행렬만 학습 | 효율적, 적은 메모리 |
| ==QLoRA== | 양자화 + LoRA | 더욱 효율적 |
| ==Adapter== | 어댑터 레이어 추가 | 모듈식 학습 |
| ==Prefix Tuning== | 프리픽스만 학습 | 경량 학습 |
## LoRA(Low-Rank Adaptation)
```
┌─────────────────────────────────────────────────┐
│                   LoRA 구조                      │
│                                                  │
│     [원본 가중치 W]  +  [ΔW = BA]               │
│        (고정)           (학습)                  │
│                                                  │
│     W: d×k 행렬 (고정)                          │
│     B: d×r 행렬 (학습)                          │
│     A: r×k 행렬 (학습)                          │
│     r << min(d,k) (저랭크)                      │
└─────────────────────────────────────────────────┘
```
## 파인튜닝 vs 프롬프트 튜닝
| 구분 | 파인튜닝 | 프롬프트 튜닝 |
|------|----------|---------------|
| 학습 대상 | 모델 가중치 | 프롬프트만 |
| 데이터 필요량 | 많음 | 적음 |
| 성능 | 높음 | 중간 |
| 비용 | 높음 | 낮음 |
| 과적합 위험 | 있음 | 낮음 |
## 파인튜닝 절차
1. ==데이터 준비==: 도메인 데이터 수집/정제
2. ==모델 선택==: 기반 모델 선택
3. ==하이퍼파라미터 설정==: 학습률, 에폭 등
4. ==학습 실행==: 파인튜닝 수행
5. ==평가==: 성능 검증
6. ==배포==: 서비스 적용
