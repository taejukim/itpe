#AI #윤리 #공정성 #필수

## 정의
AI 시스템의 불공정한 결과를 초래하는 체계적 오류, 편향
- 데이터, 알고리즘, 또는 시스템 설계에서 발생하는 체계적인 오류로 인해 특정 그룹에 불공정한 결과를 초래하는 현상
- 공정성(Fairness)을 저해하는 핵심 요소
## 키워드
* Bias, 공정성, 데이터 편향, 알고리즘 편향, Fairness
## 암기법
* 편향 유형: ==데선측알확== (데이터, 선택, 측정, 알고리즘, 확증)
* 완화 단계: ==사전-학습-사후==
## 연관 토픽
- [[AI 윤리]] - 윤리 원칙
- [[인공지능 신뢰성]] - 신뢰성 확보
- [[AI 거버넌스 (AI Governance)]] - 거버넌스
## 편향 유형
| 유형 | 설명 | 예시 |
|------|------|------|
| ==데이터 편향== | 학습 데이터의 불균형 | 특정 인종/성별 과소 대표 |
| ==선택 편향== | 데이터 수집 과정 편향 | 특정 지역만 샘플링 |
| ==측정 편향== | 측정 방식의 편향 | 불공정한 평가 기준 |
| ==알고리즘 편향== | 모델 설계상 편향 | 특정 특성에 과도한 가중치 |
| ==확증 편향== | 기존 편견 강화 | 추천 알고리즘 필터버블 |
## 편향 발생 단계
```
┌─────────────────────────────────────────────────┐
│              AI 파이프라인 편향                  │
│                                                  │
│  [데이터 수집] → [전처리] → [모델 학습] → [배포]│
│       │            │           │          │    │
│       ▼            ▼           ▼          ▼    │
│    선택편향     측정편향    알고리즘편향  피드백 │
│    표본편향     라벨편향    과적합       루프   │
└─────────────────────────────────────────────────┘
```
## 편향 탐지 방법
| 방법 | 설명 |
|------|------|
| ==그룹 간 성능 비교== | 민감 속성별 정확도 차이 |
| ==공정성 지표== | Demographic Parity, Equalized Odds |
| ==편향 감사== | 독립적 검증 및 평가 |
| ==설명가능 AI== | 의사결정 과정 분석 |
## 편향 완화 기법
| 단계 | 기법 |
|------|------|
| ==사전처리== | 데이터 리샘플링, 가중치 조정 |
| ==학습 중== | 공정성 제약 추가, 적대적 학습 |
| ==사후처리== | 임계값 조정, 결과 보정 |
## 공정성 지표
| 지표 | 설명 |
|------|------|
| Demographic Parity | 그룹 간 양성 예측 비율 동일 |
| Equalized Odds | 그룹 간 TPR, FPR 동일 |
| Individual Fairness | 유사한 개인에 유사한 결과 |
