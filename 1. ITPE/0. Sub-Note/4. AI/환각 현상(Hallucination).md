#AI #LLM #신뢰성 #필수

## 정의
AI가 사실이 아닌 정보를 생성하는 현상, 환각
- LLM이 학습 데이터에 없거나 사실과 다른 정보를 마치 사실인 것처럼 자신 있게 생성하는 현상
- 모델이 "환각"을 보는 것처럼 존재하지 않는 정보를 만들어냄
## 키워드
* Hallucination, 환각, 사실 오류, RAG, 팩트체크, 신뢰성
## 암기법
* 환각 = AI가 "보지 못한 것을 본다"
* 해결: ==RAG로 사실 검증==
## 연관 토픽
- [[RAG(Retrieval Augmented Generation)]] - 검색 증강 생성
- [[LLM]] - 대규모 언어 모델
- [[인공지능 신뢰성]] - AI 신뢰성
## 유형
| 유형 | 설명 | 예시 |
|------|------|------|
| 사실 오류 | 틀린 사실 생성 | 잘못된 날짜, 인물 정보 |
| 출처 조작 | 없는 출처 인용 | 가짜 논문, URL 생성 |
| 논리 오류 | 비논리적 추론 | 잘못된 계산, 추론 |
| 맥락 이탈 | 질문과 무관한 답변 | 주제 벗어난 응답 |
## 발생 원인
- ==학습 데이터 한계==: 불완전하거나 편향된 데이터
- ==확률적 생성==: 가장 그럴듯한 다음 토큰 예측
- ==지식 단절==: 학습 이후 정보 부재
- ==과신(Overconfidence)==: 불확실성 표현 부족
## 해결 방안
| 방안 | 설명 |
|------|------|
| ==RAG== | 외부 지식베이스 검색 후 생성 |
| ==사실 검증== | 생성 결과 팩트체크 |
| ==출처 명시== | 정보 출처 요구 |
| ==불확실성 표현== | "확실하지 않다" 표현 유도 |
| ==Fine-tuning== | 도메인 특화 학습 |
| ==RLHF== | 인간 피드백 기반 강화학습 |
## 탐지 방법
- 외부 지식베이스와 교차 검증
- 일관성 검사 (같은 질문 반복)
- 출처 확인 요청
- 전문가 검토
## 산업별 영향
| 분야 | 위험 |
|------|------|
| 의료 | 잘못된 진단/처방 정보 |
| 법률 | 허위 판례 인용 |
| 금융 | 잘못된 투자 조언 |
| 교육 | 오개념 전달 |
