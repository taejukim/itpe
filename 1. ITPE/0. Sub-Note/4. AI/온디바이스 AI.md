#AI #엣지컴퓨팅 #경량화 #필수

## 정의
디바이스에서 직접 AI를 실행하는 기술, 온디바이스 AI
- 클라우드가 아닌 스마트폰, IoT 기기 등 엣지 디바이스에서 직접 AI 추론을 수행하는 기술
- 데이터를 외부로 전송하지 않고 로컬에서 처리
## 키워드
* On-Device, 엣지 AI, NPU, 경량화, sLLM, TensorFlow Lite
## 암기법
* 온디바이스 = On(위에) + Device(기기) = 기기 위에서 AI
* 경량화: ==양가지== (양자화, 가지치기, 지식증류)
## 연관 토픽
- [[sLLM]] - 경량화 언어모델
- [[지식 증류(Knowledge Distillation)]] - 모델 압축
- [[연합학습(Federated Learning)]] - 분산 학습
- [[피지컬 AI(Physical AI)]] - 물리적 AI
## 클라우드 AI vs 온디바이스 AI
| 구분 | 클라우드 AI | 온디바이스 AI |
|------|-------------|---------------|
| 처리 위치 | 서버 | 디바이스 |
| 지연시간 | 높음 | 낮음 |
| 프라이버시 | 데이터 전송 | 로컬 처리 |
| 비용 | API 비용 | 초기 비용 |
| 오프라인 | 불가 | 가능 |
| 모델 크기 | 대형 가능 | 경량화 필요 |
## 핵심 기술
| 기술 | 설명 |
|------|------|
| ==모델 경량화== | 양자화, 가지치기, 지식증류 |
| ==sLLM== | 소형 언어 모델 |
| ==NPU== | 신경망 처리 전용 칩 |
| ==TensorFlow Lite== | 모바일용 ML 프레임워크 |
| ==Core ML== | Apple 디바이스용 ML |
| ==ONNX Runtime== | 크로스플랫폼 추론 |
## 경량화 기법
```
┌─────────────────────────────────────────────────┐
│              모델 경량화 기법                    │
│                                                  │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐     │
│  │  양자화  │  │ 가지치기 │  │ 지식증류 │     │
│  │Quantize  │  │ Pruning  │  │Distill   │     │
│  │FP32→INT8 │  │ 불필요   │  │ Teacher  │     │
│  │          │  │ 제거     │  │→Student  │     │
│  └──────────┘  └──────────┘  └──────────┘     │
└─────────────────────────────────────────────────┘
```
## 활용 분야
- ==스마트폰==: 음성인식, 얼굴인식, 사진 보정
- ==웨어러블==: 건강 모니터링, 활동 인식
- ==자동차==: ADAS, 음성 비서
- ==IoT==: 스마트홈, 산업용 센서
- ==로봇==: 실시간 인식, 제어
## 장단점
| 장점 | 단점 |
|------|------|
| 낮은 지연시간 | 제한된 연산 능력 |
| 프라이버시 보호 | 모델 크기 제한 |
| 오프라인 가능 | 업데이트 어려움 |
| 네트워크 비용 절감 | 배터리 소모 |
