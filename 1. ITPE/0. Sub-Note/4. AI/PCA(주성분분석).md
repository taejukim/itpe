#AI #머신러닝 #차원축소 #필수

## 정의
데이터의 분산을 최대화하는 차원 축소 기법, PCA
- Principal Component Analysis
- 고차원 데이터를 저차원으로 변환하면서 데이터의 분산(정보)을 최대한 보존하는 비지도학습 기법
## 키워드
* PCA, 주성분, 고유값, 고유벡터, 차원 축소, 분산
* RCA
* SOM: 또다른 차원축소 방법
## 암기법
* PCA = Principal(주요) + Component(성분) + Analysis(분석)
* 절차: ==정공고주투== (정규화, 공분산, 고유값, 주성분, 투영)
## 연관 토픽
- [[오토인코더(Autoencoder)]] - 비선형 차원 축소
- [[DBSCAN(밀도 기반 클러스터링)]] - 클러스터링
- [[서포트 벡터 머신 SVM]] - 분류
## 동작 원리
```
┌─────────────────────────────────────────────────┐
│              PCA 차원 축소                       │
│                                                  │
│  [원본 데이터]     [주성분 추출]    [저차원 투영]│
│                                                  │
│      ●              PC1 →           ●           │
│    ● ● ●              ↑           ● ● ●         │
│  ● ● ● ● ●          PC2          ● ● ● ●       │
│    ● ● ●                          ● ● ●         │
│      ●                              ●           │
│                                                  │
│  2D 데이터 → 주성분 축 → 1D 투영               │
└─────────────────────────────────────────────────┘
```
## 알고리즘 절차
1. ==데이터 정규화==: 평균 0, 분산 1로 스케일링
2. ==공분산 행렬 계산==: 특성 간 상관관계 (Coveriance)
3. ==고유값/고유벡터 계산==: 주성분 방향
4. ==주성분 선택==: 설명 분산 비율 기준
5. ==데이터 투영==: 선택된 주성분으로 변환
## 주요 개념
| 개념 | 설명 |
|------|------|
| ==주성분(PC)== | 분산이 최대인 방향의 축 |
| ==고유값== | 주성분의 분산 크기 |
| ==고유벡터== | 주성분의 방향 |
| ==설명 분산 비율== | 각 PC가 설명하는 분산 비율 |
## 주성분 선택 기준
| 방법 | 설명 |
|------|------|
| 누적 분산 비율 | 80~95% 설명하는 PC 수 |
| 스크리 플롯 | 고유값 급격히 감소하는 지점 |
| Kaiser 기준 | 고유값 > 1인 PC |
## 장단점
| 장점 | 단점 |
|------|------|
| 차원의 저주 완화 | 선형 관계만 포착 |
| 노이즈 제거 | 해석 어려움 |
| 시각화 가능 | 정보 손실 |
| 계산 효율 | 스케일 민감 |
## 활용 분야
- 데이터 시각화 (고차원 → 2D/3D)
- 노이즈 제거
- 특성 추출
- 이미지 압축
- 이상 탐지
